04/11 22:21:27 starting training
04/11 22:55:54 step 2000 epoch 1 learning rate 0.5 step-time 1.031 loss 63.613
04/11 22:56:54   test eval: loss 49.99
04/11 22:56:54 starting decoding
04/11 23:00:29 test avg_score=0.0428
04/11 23:00:29 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/11 23:00:29 finished saving model
04/11 23:25:59   decaying learning rate to: 0.495
04/11 23:34:58 step 4000 epoch 2 learning rate 0.495 step-time 1.032 loss 47.337
04/11 23:35:57   test eval: loss 43.17
04/11 23:35:57 starting decoding
04/11 23:39:25 test avg_score=0.0826
04/11 23:39:25 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/11 23:39:25 finished saving model
04/12 00:13:43 step 6000 epoch 2 learning rate 0.495 step-time 1.027 loss 42.434
04/12 00:14:42   test eval: loss 40.38
04/12 00:14:42 starting decoding
04/12 00:18:09 test avg_score=0.0880
04/12 00:18:09 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 00:18:09 finished saving model
04/12 00:34:40   decaying learning rate to: 0.49
04/12 00:52:26 step 8000 epoch 3 learning rate 0.49 step-time 1.026 loss 39.107
04/12 00:53:25   test eval: loss 37.41
04/12 00:53:25 starting decoding
04/12 00:56:51 test avg_score=0.1313
04/12 00:56:51 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 00:56:52 finished saving model
04/12 01:32:58 step 10000 epoch 3 learning rate 0.49 step-time 1.081 loss 36.749
04/12 01:34:13   test eval: loss 36.29
04/12 01:34:13 starting decoding
04/12 01:38:19 test avg_score=0.1448
04/12 01:38:19 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 01:38:19 finished saving model
04/12 01:48:14   decaying learning rate to: 0.485
04/12 02:18:23 step 12000 epoch 4 learning rate 0.485 step-time 1.200 loss 34.488
04/12 02:19:31   test eval: loss 34.15
04/12 02:19:31 starting decoding
04/12 02:23:17 test avg_score=0.1575
04/12 02:23:17 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 02:23:17 finished saving model
04/12 03:00:08   decaying learning rate to: 0.48
04/12 03:01:26 step 14000 epoch 5 learning rate 0.48 step-time 1.143 loss 33.120
04/12 03:02:34   test eval: loss 32.71
04/12 03:02:34 starting decoding
04/12 03:06:20 test avg_score=0.1771
04/12 03:06:20 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 03:06:21 finished saving model
04/12 03:44:35 step 16000 epoch 5 learning rate 0.48 step-time 1.145 loss 31.131
04/12 03:45:43   test eval: loss 31.68
04/12 03:45:43 starting decoding
04/12 03:49:30 test avg_score=0.1864
04/12 03:49:30 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 03:49:30 finished saving model
04/12 04:16:29   decaying learning rate to: 0.475
04/12 04:27:38 step 18000 epoch 6 learning rate 0.475 step-time 1.142 loss 30.248
04/12 04:28:44   test eval: loss 31.51
04/12 04:28:44 starting decoding
04/12 04:32:30 test avg_score=0.1998
04/12 04:32:30 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 04:32:30 finished saving model
04/12 05:10:47 step 20000 epoch 6 learning rate 0.475 step-time 1.146 loss 29.096
04/12 05:11:54   test eval: loss 30.59
04/12 05:11:54 starting decoding
04/12 05:15:41 test avg_score=0.2077
04/12 05:15:41 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 05:15:42 finished saving model
04/12 05:32:51   decaying learning rate to: 0.471
04/12 05:53:53 step 22000 epoch 7 learning rate 0.471 step-time 1.143 loss 27.890
04/12 05:55:00   test eval: loss 29.98
04/12 05:55:00 starting decoding
04/12 05:58:46 test avg_score=0.2227
04/12 05:58:46 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 05:58:46 finished saving model
04/12 06:36:55 step 24000 epoch 7 learning rate 0.471 step-time 1.142 loss 27.342
04/12 06:38:02   test eval: loss 29.35
04/12 06:38:02 starting decoding
04/12 06:41:49 test avg_score=0.2303
04/12 06:41:49 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 06:41:50 finished saving model
04/12 06:49:07   decaying learning rate to: 0.466
04/12 07:20:04 step 26000 epoch 8 learning rate 0.466 step-time 1.145 loss 25.945
04/12 07:21:11   test eval: loss 29.02
04/12 07:21:11 starting decoding
04/12 07:25:02 test avg_score=0.2361
04/12 07:25:02 saving model to ../emse-data(sbt_code_hb)/model/hybrid/checkpoints
04/12 07:25:02 finished saving model
04/12 08:00:33   decaying learning rate to: 0.461
